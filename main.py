import asyncio
import logging
import sys
from aiogram import Bot, Dispatcher
from aiogram.filters import CommandStart, StateFilter
from aiogram.types import (
    Message,
    InlineKeyboardMarkup,
    InlineKeyboardButton,
    WebAppInfo,
    CallbackQuery,
)
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from aiogram import F, Router

from generate import a_generate

router = Router()


class PleaseStop(StatesGroup):
    wait = State()


import os
from dotenv import load_dotenv

load_dotenv()
MAX_MESSAGE_LENGTH = 4500
TOKEN = os.getenv("TOKEN")
TOKEN_DEEP_SEEK = os.getenv("TOKEN_DEEP_SEEK")

logging.basicConfig(level=logging.INFO, stream=sys.stdout)

bot = Bot(token=TOKEN)
dp = Dispatcher()
dp.include_router(router)


@dp.message(CommandStart())
async def command_brone_handler(message: Message) -> None:
    markup = InlineKeyboardMarkup(
        inline_keyboard=[
            [
                InlineKeyboardButton(
                    text="ÐžÑ‚ÐºÑ€Ñ‹Ñ‚ÑŒ ÐœÑƒÐ·Ð§Ð°Ñ‚",
                    web_app=WebAppInfo(url="https://getstarthealth.github.io/Obmen/"),
                ),
                InlineKeyboardButton(text="Ð”Ð¸Ð°Ð»Ð¾Ð³ Ñ Ð˜Ð˜", callback_data="deepSeek"),
            ]
        ]
    )
    await message.answer(
        text=(
            "ðŸŽµ Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ Ð² Ð½Ð°Ñˆ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼Ð¸Ñ€! "
            "Ð—Ð´ÐµÑÑŒ Ð²Ð°Ñ Ð¶Ð´ÑƒÑ‚ Ð»ÑŽÐ±Ð¸Ð¼Ñ‹Ðµ Ñ‚Ñ€ÐµÐºÐ¸ Ð¸ Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÑÑŽÑ‰Ð¸Ðµ ÐºÐ»Ð¸Ð¿Ñ‹. ðŸŽ¶\n\n"
            "âœ¨ ÐœÐµÑ‡Ñ‚Ð°ÐµÑ‚Ðµ Ð¾ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸? "
            "Ð—Ð°ÐºÐ°Ð¶Ð¸Ñ‚Ðµ ÑÐºÑÐºÐ»ÑŽÐ·Ð¸Ð²Ð½Ð¾Ðµ Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ, ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ð¾Ðµ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ Ð´Ð»Ñ Ð²Ð°Ñ! ðŸŽ¼\n\n"
            "ðŸ¤– Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚Ð° Ð´Ð»Ñ Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÐºÐ¸Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¸ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸Ð´ÐµÐ¹. ðŸš€"
        ),
        reply_markup=markup,
    )


@dp.callback_query(lambda c: c.data == "deepSeek")
async def callback_deepSeek(call: CallbackQuery):
    await call.answer()
    await call.message.answer("Ð”Ð¸Ð°Ð»Ð¾Ð³ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚, Ð·Ð°Ð´Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð·Ð°Ð¿Ñ€Ð¾Ñ")


@router.message(StateFilter(PleaseStop.wait))
async def stop_flood_please(message: Message):
    await message.answer("ÐŸÑ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ñ€ÑƒÐ³Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°... ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ.")


@router.message()
async def generating(message: Message, state: FSMContext):
    if message.text:
        await message.answer("ÐšÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°...â³")
        await state.set_state(PleaseStop.wait) 
        res = await a_generate(message.text)
        
        def split_text(text, max_length=MAX_MESSAGE_LENGTH):
            return [text[i:i+max_length] for i in range(0, len(text), max_length)]

        for chunk in split_text(res):
            await message.answer(chunk)
            
        await state.clear()

async def main() -> None:

    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
